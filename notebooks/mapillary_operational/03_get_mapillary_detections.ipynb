{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b042d1c6-a2eb-4e39-87ab-4e9846ff346a",
   "metadata": {},
   "source": [
    "# FKA get_mapillary_metadata\n",
    "\n",
    "## This script downloads a single image, extracts and stores key metadata.\n",
    "\n",
    "## Dataframes of import\n",
    "\n",
    "1) df_metadata: captures basic info about the image. image id, dimensions, etc.\n",
    "2) df_detections: normalized detection coordinates, ready to plot\n",
    "\n",
    "## Storing results in sqlite\n",
    "\n",
    "I'm not sure what's the smarter thing to store. df_segments with the base64 encoding, or df_detection_coords.\n",
    "I elected to go for df_detection_coords as the normalization code is lengthy and confusing. The downside is\n",
    "you have to remember to serialize the resulting list column before storing and then deserialize after loading.\n",
    "\n",
    "So either way there's a bit of a non-standard process one has to go through when loading from sqlite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c6d45cab-ea98-4802-9a9a-96685affe327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 'D://projects_working_directories//imagery_analysis//20250225_los_angeles_3//' already exists.\n",
      "Folder 'D://projects_working_directories//imagery_analysis//20250225_los_angeles_3////images' already exists.\n",
      "Folder 'D://projects_working_directories//imagery_analysis//20250225_los_angeles_3////images_metadata' already exists.\n",
      "Folder 'D://projects_working_directories//imagery_analysis//20250225_los_angeles_3////output' already exists.\n"
     ]
    }
   ],
   "source": [
    "%run set_environment.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4b74be26-0ef1-4eff-90d0-ce752e60ff84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_ids = ['109450931235292']\n",
    "#image_id_input_file = f\"{base_dir}//LA_roads_clipped_points-20-subset_images.xlsx\"\n",
    "is_restart = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00d5524-6f70-4c28-9413-9ab3b6f5b7be",
   "metadata": {},
   "source": [
    "# Download image and get geometries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9fe6a053-5e57-4fdd-b53d-7965844c1bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from os import getenv\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import sqlite3\n",
    "import json\n",
    "import time\n",
    "\n",
    "import mapillary_utils as mu\n",
    "import detection_analysis_utils as dau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dbd91e35-9e73-4e2c-af44-d376f943900e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image source - db or excel\n",
    "# load sampled images \n",
    "def load_image_metadata():\n",
    "    conn = sqlite3.connect(f'{image_metadata_folder}//{sqlite3_dbname}.db')\n",
    "    df_image_metadata = pd.read_sql('select * from sampled_images', conn)\n",
    "    #df_image_metadata = pd.read_sql('select * from image_metadata', conn)\n",
    "    #df_image_segmentations = pd.read_sql('select * from image_segmentations', conn)\n",
    "    conn.close()\n",
    "    return df_image_metadata\n",
    "\n",
    "df_image_metadata = load_image_metadata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "da7d2b90-ffc5-4881-9c06-e073605299a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_lat</th>\n",
       "      <th>image_lon</th>\n",
       "      <th>residual</th>\n",
       "      <th>image_id</th>\n",
       "      <th>camera_type</th>\n",
       "      <th>is_pano</th>\n",
       "      <th>camera_focal_len</th>\n",
       "      <th>camera_k1</th>\n",
       "      <th>camera_k2</th>\n",
       "      <th>image_path</th>\n",
       "      <th>error</th>\n",
       "      <th>image_url</th>\n",
       "      <th>captured_at</th>\n",
       "      <th>captured_on</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>34.085388</td>\n",
       "      <td>-118.412936</td>\n",
       "      <td>228.932747</td>\n",
       "      <td>3696058567304307</td>\n",
       "      <td>perspective</td>\n",
       "      <td>0</td>\n",
       "      <td>0.46338888335247</td>\n",
       "      <td>-0.1586875276244</td>\n",
       "      <td>0.026124399135413</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://scontent.ffsd3-1.fna.fbcdn.net/m1/v/t6...</td>\n",
       "      <td>1710345504000</td>\n",
       "      <td>2024-03-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>34.064565</td>\n",
       "      <td>-118.413076</td>\n",
       "      <td>162.935513</td>\n",
       "      <td>1610188043077471</td>\n",
       "      <td>perspective</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4807445264723</td>\n",
       "      <td>-0.13772377073186</td>\n",
       "      <td>0.019659951305129</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://scontent.ffsd3-1.fna.fbcdn.net/m1/v/t6...</td>\n",
       "      <td>1710427765000</td>\n",
       "      <td>2024-03-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_lat   image_lon    residual          image_id  camera_type  \\\n",
       "190  34.085388 -118.412936  228.932747  3696058567304307  perspective   \n",
       "125  34.064565 -118.413076  162.935513  1610188043077471  perspective   \n",
       "\n",
       "     is_pano  camera_focal_len          camera_k1          camera_k2  \\\n",
       "190        0  0.46338888335247   -0.1586875276244  0.026124399135413   \n",
       "125        0   0.4807445264723  -0.13772377073186  0.019659951305129   \n",
       "\n",
       "    image_path error                                          image_url  \\\n",
       "190       None  None  https://scontent.ffsd3-1.fna.fbcdn.net/m1/v/t6...   \n",
       "125       None  None  https://scontent.ffsd3-1.fna.fbcdn.net/m1/v/t6...   \n",
       "\n",
       "       captured_at captured_on  \n",
       "190  1710345504000  2024-03-13  \n",
       "125  1710427765000  2024-03-14  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_image_metadata.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "de66fc79-259b-4bb9-bd59-98e32b4cb386",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get input ids from sqlite\n",
    "image_ids = list(set(df_image_metadata.image_id.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "44a1056a-76e8-46ac-83d1-632d1c4e61cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## alt - load image ids from a file\n",
    "#df_input_ids = pd.read_excel(image_id_input_file)\n",
    "#image_ids = list(set(df_input_ids.image_id.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "692a9549-52c9-4c44-ad05-ea79c295af91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata = pd.DataFrame(columns=['guid', 'image_source', 'image_id', 'captured_at_unix', 'lat', 'lon',\n",
    "       'original_height', 'original_width', 'height', 'width', 'camera_type',\n",
    "       'sequence', 'compass_angle', 'computed_compass_angle', 'is_pano',\n",
    "       'camera_focal_len', 'camera_k1', 'camera_k2', 'altitude',\n",
    "       'image_path_on_disk'])\n",
    "\n",
    "df_detections = pd.DataFrame(columns=['image_id', 'detection_id','detection_label','feature_id','image_height','image_width','extent','properties','coordinates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4d14c7c9-3357-436a-87ed-9bd5d742cd44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "769\n",
      "62\n",
      "714\n"
     ]
    }
   ],
   "source": [
    "## skip this cell\n",
    "\n",
    "if is_restart == True:\n",
    "    \n",
    "    ## load existing data\n",
    "    df_metadata = pd.read_excel(f\"{image_metadata_folder}//sample_image_metadata.xlsx\")\n",
    "    df_detections = pd.read_excel(f\"{image_metadata_folder}//sample_image_detections.xlsx\")\n",
    "    \n",
    "    ## get already completed items\n",
    "    completed_ids = df_metadata.image_id.astype(str).tolist()\n",
    "\n",
    "    print(len(image_ids))\n",
    "\n",
    "    image_ids = list(set(image_ids) - set(completed_ids))\n",
    "    \n",
    "    print(len(image_ids))\n",
    "    print(len(completed_ids))\n",
    "\n",
    "else:\n",
    "    ## initialize the necessary dfs\n",
    "    df_metadata = pd.DataFrame(columns=['guid', 'image_source', 'image_id', 'captured_at_unix', 'lat', 'lon',\n",
    "       'original_height', 'original_width', 'height', 'width', 'camera_type',\n",
    "       'sequence', 'compass_angle', 'computed_compass_angle', 'is_pano',\n",
    "       'camera_focal_len', 'camera_k1', 'camera_k2', 'altitude',\n",
    "       'image_path_on_disk'])\n",
    "    df_detections = pd.DataFrame(columns=['image_id', 'detection_id','detection_label','feature_id','image_height','image_width','extent','properties','coordinates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a27d670e-7557-46f0-9c1d-4c311e0c05c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "API_KEY = getenv(\"MAPILLARY_CLIENT_TOKEN\")\n",
    "\n",
    "## vars established by set_environment.py\n",
    "# base_dir - root directory for working files\n",
    "# image_folder - fully qualified folder where images are stored\n",
    "# image_metadata_folder - fully qualified folder where image_metadata is stored\n",
    "# sqlite3_dbname - fully qualified database file name\n",
    "# output_folder - default location to write output files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e1313dda-0215-4d87-986e-e1424909fdde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ericf\\AppData\\Local\\Temp\\ipykernel_9108\\1509053384.py:57: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_metadata = pd.concat([df_metadata, temp_meta])\n",
      "C:\\Users\\ericf\\AppData\\Local\\Temp\\ipykernel_9108\\1509053384.py:57: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_metadata = pd.concat([df_metadata, temp_meta])\n",
      "C:\\Users\\ericf\\AppData\\Local\\Temp\\ipykernel_9108\\1509053384.py:57: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_metadata = pd.concat([df_metadata, temp_meta])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ericf\\AppData\\Local\\Temp\\ipykernel_9108\\1509053384.py:57: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_metadata = pd.concat([df_metadata, temp_meta])\n",
      "C:\\Users\\ericf\\AppData\\Local\\Temp\\ipykernel_9108\\1509053384.py:57: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_metadata = pd.concat([df_metadata, temp_meta])\n",
      "C:\\Users\\ericf\\AppData\\Local\\Temp\\ipykernel_9108\\1509053384.py:57: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_metadata = pd.concat([df_metadata, temp_meta])\n",
      "C:\\Users\\ericf\\AppData\\Local\\Temp\\ipykernel_9108\\1509053384.py:57: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_metadata = pd.concat([df_metadata, temp_meta])\n",
      "C:\\Users\\ericf\\AppData\\Local\\Temp\\ipykernel_9108\\1509053384.py:57: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_metadata = pd.concat([df_metadata, temp_meta])\n",
      "C:\\Users\\ericf\\AppData\\Local\\Temp\\ipykernel_9108\\1509053384.py:57: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_metadata = pd.concat([df_metadata, temp_meta])\n",
      "C:\\Users\\ericf\\AppData\\Local\\Temp\\ipykernel_9108\\1509053384.py:57: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_metadata = pd.concat([df_metadata, temp_meta])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ericf\\AppData\\Local\\Temp\\ipykernel_9108\\1509053384.py:57: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_metadata = pd.concat([df_metadata, temp_meta])\n",
      "C:\\Users\\ericf\\AppData\\Local\\Temp\\ipykernel_9108\\1509053384.py:57: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_metadata = pd.concat([df_metadata, temp_meta])\n",
      "C:\\Users\\ericf\\AppData\\Local\\Temp\\ipykernel_9108\\1509053384.py:57: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_metadata = pd.concat([df_metadata, temp_meta])\n",
      "C:\\Users\\ericf\\AppData\\Local\\Temp\\ipykernel_9108\\1509053384.py:57: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_metadata = pd.concat([df_metadata, temp_meta])\n",
      "C:\\Users\\ericf\\AppData\\Local\\Temp\\ipykernel_9108\\1509053384.py:57: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_metadata = pd.concat([df_metadata, temp_meta])\n",
      "C:\\Users\\ericf\\AppData\\Local\\Temp\\ipykernel_9108\\1509053384.py:57: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_metadata = pd.concat([df_metadata, temp_meta])\n",
      "C:\\Users\\ericf\\AppData\\Local\\Temp\\ipykernel_9108\\1509053384.py:57: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_metadata = pd.concat([df_metadata, temp_meta])\n",
      "C:\\Users\\ericf\\AppData\\Local\\Temp\\ipykernel_9108\\1509053384.py:57: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_metadata = pd.concat([df_metadata, temp_meta])\n",
      "C:\\Users\\ericf\\AppData\\Local\\Temp\\ipykernel_9108\\1509053384.py:57: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_metadata = pd.concat([df_metadata, temp_meta])\n",
      "C:\\Users\\ericf\\AppData\\Local\\Temp\\ipykernel_9108\\1509053384.py:57: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_metadata = pd.concat([df_metadata, temp_meta])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ericf\\AppData\\Local\\Temp\\ipykernel_9108\\1509053384.py:57: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_metadata = pd.concat([df_metadata, temp_meta])\n"
     ]
    }
   ],
   "source": [
    "def get_and_process_detections(image_id, API_KEY, image_size_indicator='thumb_original_url', image_dir=image_folder, step_down=.01):\n",
    "    # get the image and metadata\n",
    "    image, metadata = mu.get_mapillary_image(image_id, API_KEY, image_size_indicator='thumb_original_url', image_dir=image_folder)\n",
    "\n",
    "    try:\n",
    "        if metadata.get('error') == 'error':\n",
    "            df_metadata = pd.DataFrame.from_dict([{'image_id':image_id}])\n",
    "            df_detections = pd.DataFrame.from_dict([{'image_id':image_id}])\n",
    "            return df_metadata, df_detections\n",
    "    except: # if metadata is NoneType\n",
    "        df_metadata = pd.DataFrame.from_dict([{'image_id':image_id}])\n",
    "        df_detections = pd.DataFrame.from_dict([{'image_id':image_id}])\n",
    "        return df_metadata, df_detections\n",
    "        \n",
    "    df_metadata = pd.DataFrame.from_dict([metadata])\n",
    "    \n",
    "    # get the detections and extract them\n",
    "    detections = mu.get_mapillary_detections(image_id, API_KEY)\n",
    "    df_segments = mu.extract_detections(detections)\n",
    "    \n",
    "    #merge w/ metadata so can accesss height/width\n",
    "    df_segments = pd.merge(df_segments,df_metadata, left_on='image_id', right_on='image_id')\n",
    "    \n",
    "    # decode detections\n",
    "    arrays = df_segments.apply(lambda x: mu.decode_base64_geometry_fromdf(x, normalize=True, image_height=x.height, image_width=x.width), axis=1)\n",
    "    \n",
    "    df_detections = pd.DataFrame(columns=['image_id', 'detection_id','detection_label','feature_id','image_height','image_width','extent','properties','coordinates'])\n",
    "    \n",
    "    #must iterate through like this because for any given detection there can be multiple arrays\n",
    "    for array in arrays:\n",
    "        for row in array:\n",
    "            try:\n",
    "                df_detections.loc[len(df_detections)] = [row[0],row[1],row[2],row[3],row[4],row[5],row[6],row[7],row[8]]\n",
    "            except:\n",
    "                print(f\"could not add to df_detections: {image_id}\")\n",
    "    \n",
    "    \n",
    "    ## get relative pixel count per detection\n",
    "    df_detections['relative_pixel_count'] = df_detections.coordinates.apply(dau.detect_relative_pixel_count, step_down=step_down)\n",
    "    \n",
    "    # Group by 'image_id' and calculate the sum of 'Value' for each category\n",
    "    #df_detections['relative_image_pixel_count'] = df_detections.groupby('image_id')['relative_pixel_count'].transform('sum')\n",
    "    #changing calculation to take the whole image instead of just detections\n",
    "    df_detections['relative_image_pixel_count'] = df_detections.apply(lambda x: (x.image_height * step_down) * (x.image_width * step_down), axis=1)\n",
    "    df_detections['percent_of_image'] = df_detections.apply(\n",
    "        lambda x: (x.relative_pixel_count / x.relative_image_pixel_count)*100 if x.relative_image_pixel_count != 0 else 0\n",
    "    , axis=1)\n",
    "    \n",
    "    return df_metadata, df_detections\n",
    "\n",
    "i = 0\n",
    "for image_id in image_ids:\n",
    "    i +=1\n",
    "    if i % 20 == 0:\n",
    "        print(i)\n",
    "    temp_meta, temp_detect = get_and_process_detections(image_id, API_KEY, image_size_indicator='thumb_original_url', image_dir=image_folder)\n",
    "    df_metadata = pd.concat([df_metadata, temp_meta])\n",
    "    df_detections = pd.concat([df_detections, temp_detect])\n",
    "\n",
    "    time.sleep(1)\n",
    "    \n",
    "    #df_detections = pd.concat([df_detections, get_and_process_detections(image_id, API_KEY, image_size_indicator='thumb_original_url', image_dir=image_folder)])\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "977767ab-ceb3-4ad5-98dd-1a01a74932b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## backup to excel before dropping columns\n",
    "df_metadata.to_excel(f\"{image_metadata_folder}//sample_image_metadata.xlsx\", index=False)\n",
    "df_metadata.to_csv(f\"{image_metadata_folder}//sample_image_metadata.csv\", index=False)\n",
    "\n",
    "df_detections = df_detections.sort_values(by=['image_id','percent_of_image'], ascending=False)\n",
    "df_detections.to_excel(f\"{image_metadata_folder}//sample_image_detections.xlsx\", index=False)\n",
    "df_detections.to_csv(f\"{image_metadata_folder}//sample_image_detections.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5830afba-62f2-4823-99f1-c4488cbe883b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_detections = df_detections.drop(columns=['properties','coordinates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "42b76dc8-bec4-4ecc-9b2b-84b9c091e4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "db_file = f'{image_metadata_folder}//{sqlite3_dbname}.db'\n",
    "\n",
    "conn = sqlite3.connect(db_file)\n",
    "\n",
    "df_detections.to_sql('image_detections', con=conn, if_exists='replace', index=False)\n",
    "\n",
    "\n",
    "\n",
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9a6c9a-28d5-44db-be66-66d945671cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
